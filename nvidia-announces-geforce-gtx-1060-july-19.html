<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Starting at $249, Available July 19th | PeakDash</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="Excitingly, GPU Season 2016 is now in full swing. In the last two months we have seen NVIDIA launch a pair of high-end cards – the Pascal-based GeForce GTX 1080 and GTX 1070 – and just last week rival AMD launched their first card based on their Polaris architecture, the mainstream-focused Radeon RX 480. Powered by TSMC’s 16nm FinFET process and GlobalFoundries’ 14nm FinFET process respectively, NVIDIA and AMD have delivered better performance for lower prices, and with lower power consumption as well."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>PeakDash</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>Starting at $249, Available July 19th</h1><div><strong>Publish date: </strong>2024-04-08</div><p>Excitingly, GPU Season 2016 is now in full swing. In the last two months we have seen NVIDIA launch a pair of high-end cards – the Pascal-based <a href=#>GeForce GTX 1080</a> and <a href=#>GTX 1070</a> – and just last week rival AMD launched their first card based on their Polaris architecture, the mainstream-focused <a href=#>Radeon RX 480</a>. Powered by TSMC’s 16nm FinFET process and GlobalFoundries’ 14nm FinFET process respectively, NVIDIA and AMD have delivered better performance for lower prices, and with lower power consumption as well.</p><p>Of course no GPU product stack is complete with just a single chip and a handful of cards, and over the coming months we are going to see both vendors rolling out the rest of their respective stacks. To that end, kicking off this second wave of updates today is NVIDIA, who in traditional top-to-bottom fashion is announcing the next card in their product stack, GeForce GTX 1060. Powered by the company’s new GP106 GPU, GTX 1060 will be NVIDIA’s play at the mainstream/enthusiast market.</p><table align=center border=1 bordercolor=#dddddd cellpadding=3 cellspacing=0 width=650><tbody readability=1><tr class=tgrey readability=2><td align=center colspan=7>NVIDIA GPU Specification Comparison</td></tr><tr class=tlblue><td align=center bgcolor=#016a96 class=contentwhite width=168>&nbsp;</td><td align=center bgcolor=#016a96 class=contentwhite width=110>GTX 1080</td><td align=center bgcolor=#016a96 class=contentwhite width=110>GTX 1070</td><td align=center bgcolor=#016a96 class=contentwhite width=110>GTX 1060</td><td align=center bgcolor=#016a96 class=contentwhite width=110>GTX 960</td></tr><tr><td class=tlgrey><strong>CUDA Cores</strong></td><td align=center bgcolor=#f7f7f7>2560</td><td align=center bgcolor=#f7f7f7>1920</td><td align=center bgcolor=#f7f7f7>1280</td><td align=center bgcolor=#f7f7f7>1024</td></tr><tr><td class=tlgrey><strong>Texture Units</strong></td><td align=center bgcolor=#f7f7f7>160</td><td align=center bgcolor=#f7f7f7>120</td><td align=center bgcolor=#f7f7f7>80</td><td align=center bgcolor=#f7f7f7>64</td></tr><tr><td class=tlgrey><strong>ROPs</strong></td><td align=center bgcolor=#f7f7f7>64</td><td align=center bgcolor=#f7f7f7>64</td><td align=center bgcolor=#f7f7f7>48?</td><td align=center bgcolor=#f7f7f7>32</td></tr><tr><td class=tlgrey><strong>Core Clock</strong></td><td align=center bgcolor=#f7f7f7>1607MHz</td><td align=center bgcolor=#f7f7f7>1506MHz</td><td align=center bgcolor=#f7f7f7>?</td><td align=center bgcolor=#f7f7f7>1126MHz</td></tr><tr><td class=tlgrey><strong>Boost Clock</strong></td><td align=center bgcolor=#f7f7f7>1733MHz</td><td align=center bgcolor=#f7f7f7>1683MHz</td><td align=center bgcolor=#f7f7f7>1700MHz</td><td align=center bgcolor=#f7f7f7>1178MHz</td></tr><tr><td class=tlgrey><strong>TFLOPs (FMA)</strong></td><td align=center bgcolor=#f7f7f7>8.9 TFLOPs</td><td align=center bgcolor=#f7f7f7>6.5 TFLOPs</td><td align=center bgcolor=#f7f7f7>4.4 TFLOPs</td><td align=center bgcolor=#f7f7f7>2.4 TFLOPs</td></tr><tr><td class=tlgrey><strong>Memory Clock</strong></td><td align=center bgcolor=#f7f7f7>10Gbps GDDR5X</td><td align=center bgcolor=#f7f7f7>8Gbps GDDR5</td><td align=center bgcolor=#f7f7f7>8Gbps GDDR5</td><td align=center bgcolor=#f7f7f7>7Gbps GDDR5</td></tr><tr><td class=tlgrey><strong>Memory Bus Width</strong></td><td align=center bgcolor=#f7f7f7>256-bit</td><td align=center bgcolor=#f7f7f7>256-bit</td><td align=center bgcolor=#f7f7f7>192-bit</td><td align=center bgcolor=#f7f7f7>128-bit</td></tr><tr><td class=tlgrey><strong>VRAM</strong></td><td align=center bgcolor=#f7f7f7>8GB</td><td align=center bgcolor=#f7f7f7>8GB</td><td align=center bgcolor=#f7f7f7>6GB</td><td align=center bgcolor=#f7f7f7>2GB</td></tr><tr><td class=tlgrey><strong>FP64</strong></td><td align=center bgcolor=#f7f7f7>1/32</td><td align=center bgcolor=#f7f7f7>1/32</td><td align=center bgcolor=#f7f7f7>1/32?</td><td align=center bgcolor=#f7f7f7>1/32</td></tr><tr><td class=tlgrey><strong>TDP</strong></td><td align=center bgcolor=#f7f7f7>180W</td><td align=center bgcolor=#f7f7f7>150W</td><td align=center bgcolor=#f7f7f7>120W</td><td align=center bgcolor=#f7f7f7>120W</td></tr><tr><td class=tlgrey><strong>GPU</strong></td><td align=center bgcolor=#f7f7f7>GP104</td><td align=center bgcolor=#f7f7f7>GP104</td><td align=center bgcolor=#f7f7f7>GP106</td><td align=center bgcolor=#f7f7f7>GM204</td></tr><tr><td class=tlgrey><strong>Transistor Count</strong></td><td align=center bgcolor=#f7f7f7>7.2B</td><td align=center bgcolor=#f7f7f7>7.2B</td><td align=center bgcolor=#f7f7f7>?</td><td align=center bgcolor=#f7f7f7>2.94B</td></tr><tr><td class=tlgrey><strong>Manufacturing Process</strong></td><td align=center bgcolor=#f7f7f7>TSMC 16nm</td><td align=center bgcolor=#f7f7f7>TSMC 16nm</td><td align=center bgcolor=#f7f7f7>TSMC 16nm</td><td align=center bgcolor=#f7f7f7>TSMC 28nm</td></tr><tr><td class=tlgrey><strong>Launch Date</strong></td><td align=center bgcolor=#f7f7f7>05/27/2016</td><td align=center bgcolor=#f7f7f7>06/10/2016</td><td align=center bgcolor=#f7f7f7>07/19/2016</td><td align=center bgcolor=#f7f7f7>01/22/2015</td></tr><tr><td class=tlgrey><strong>Launch Price</strong></td><td align=center bgcolor=#f7f7f7>MSRP: $599<br>Founders $699</td><td align=center bgcolor=#f7f7f7>MSRP: $379<br>Founders $449</td><td align=center bgcolor=#f7f7f7>MSRP: $249<br>Founders $299</td><td align=center bgcolor=#f7f7f7>$199</td></tr></tbody></table><p>When it came to building the Maxwell 2 generation, NVIDIA designed GM206 as half of a GM204; half of the CUDA Cores, half of the ROPs, half of the memory bandwidth, etc. It allowed for a very straightforward progression from the bottom of the Maxwell 2 family to the top of it, maintaining the same resource balance between all of the GPUs. For the Pascal generation in turn, NVIDIA has done much the same here.</p><p>Diving into the specifications then, GTX 1060 and its GP106 GPU ships with 1280 CUDA cores, which is half the number found on GTX 1080/GP104. Similarly, this means we’re looking at half the texture units, and half of the polymorph geometry engines. At this point NVIDIA has not provided an architecture diagram for GP106, so I don’t know how NVIDIA has laid out the internal working of the card, but we’ll be looking at 10 Pascal SMs in some configuration.</p><p>However on the backend of the rendering pipeline, things are a bit more interesting NVIDIA deviates a bit from tradition, and a bit from making GP106 a true halving of GP104. Whereas you’d expect half of a GP104 to ship with a 128-bit memory bus, NVIDIA has defied expectations by giving GP106 a larger 192-bit memory bus, giving the chip 50% more memory bandwidth per CUDA core, all things held equal. NVIDIA’s no stranger to 192-bit memory buses – in fact GK106 had one – but after Maxwell, this comes as a bit of a surprise.</p><p>As this is only a brief introduction on NVIDIA’s part – little more than a teaser – I’m sure we’ll find out more about their architectural decisions in time for the full review, but I suspect that the larger bus is a compromise solution for coming up with more memory bandwidth versus <a href=#>GTX 960/GM206</a>. Relative to their Maxwell predecessors, all of the other Pascal parts so far have received significant bandwidth increases in order to feed their faster GPUs. For GTX 1080 this was GDDR5X, and for GTX 1070 this was faster 8 Gbps GDDR5 combined with a unified 256-bit memory bus. For GP106 to follow this path, NVIDIA would need to either implement GDDR5X (a more costly and volume-limited technology at this time), or go with a wider memory bus, and the company has seemingly opted for the latter.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=575><tbody readability=1><tr class=tgrey readability=2><td align=center colspan=6>NVIDIA Compute To Memory Bandwidth Ratios</td></tr><tr class=tlblue><td align=center class=tlgrey valign=middle width=190>Video Card</td><td align=center valign=middle width=190>FLOPs-per-byte</td><td align=center valign=middle width=191>Total Memory Bandwidth</td></tr><tr><td align=center class=tlgrey valign=middle>GTX 1080</td><td align=center valign=middle>25.8</td><td align=center valign=middle>320GB/sec</td></tr><tr><td align=center class=tlgrey valign=middle>GTX 1070</td><td align=center valign=middle>23.5</td><td align=center valign=middle>256GB/sec</td></tr><tr><td align=center class=tlgrey valign=middle>GTX 1060</td><td align=center valign=middle>21.1</td><td align=center valign=middle>192GB/sec</td></tr><tr><td align=center class=tlgrey valign=middle>GTX 960</td><td align=center valign=middle>20</td><td align=center valign=middle>112GB/sec</td></tr><tr><td align=center class=tlgrey valign=middle>GTX 660</td><td align=center valign=middle>12.8</td><td align=center valign=middle>144GB/sec</td></tr></tbody></table><p>In any case, the 192-bit memory bus also means that we may see an increase in the number of ROPs on the card. NVIDIA has not disclosed the ROP count, but Pascal’s internal ROP/L2/memory controller partition design means that we’re going to be looking at 6 partitions, which at 8 ROPs per would work out to 48 ROPs. If this is the case, then not only would GTX 1060 be receiving a significant boost in memory bandwidth versus its predecessor, but it would be receiving a significant increase in raw pixel throughput as well. So it will be interesting to see what the final specifications turn out to be. Note that this could also impact the raster engine count – to maintain perfect balance, Pascal needs a raster engine for every 16 ROPs – but at this point that’s a bit more conjectural.</p><p>Moving on to clockspeeds, the GTX 1060 will be shipping with a 1.7GHz boost clock, which is smack-dab in the middle of the boost clocks for the GTX 1080 and GTX 1070. In other words, the card will be clocked just as high as its higher-end siblings, and the only difference will be the overall number of processing units within the GPU. On a pure SM basis this puts GTX 1060 at 4.35 TFLOPs, giving the card 67% of the compute and geometry performance of the GTX 1070. Or to compare it to the outgoing GTX 960, we’re looking at an 80% increase in those same metrics.</p><p>Backing the GP106 GPU is the aforementioned GDDR5 memory. Owing to its non-power-of-two memory bus size, GTX 1060 will be shipping with 6GB of VRAM, which is 2GB less than the GP104 cards and 2-4GB more than the older GTX 960. The card will use the same 8Gbps memory as on GTX 1070, giving the card 192GB/sec of total memory bandwidth, a hefty 71% increase over GTX 960. Combined with the increased memory compression efficiency of Pascal, it goes without saying that GTX 1060 should not find itself wanting for memory bandwidth.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/10474/Stacked_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Rounding out the package, let’s talk about power and thermals. NVIDIA is slotting GTX 1060 in the same TDP envelope as the outgoing GTX 960, which means 120W, making the GTX 1060 their flagship sub-150W card. We’ll of course see just how well they adhere to that in our full review, but the basic idea is that GTX 1060 should be a drop-in replacement for GTX 960, an important consideration for the sub-150W market that the card is aimed at.</p><p>In terms of performance, NVIDIA hasn’t published any internal benchmarks, but they have been rather explicit that they’re targeting GTX 980 performance. Given what we’ve seen of Pascal so far, there’s good reason to believe that a 1280 CUDA core GPU should be able to come close, though it’s going to depend on the game. My best guess is that baring more extensive power throttling, GTX 1060 should be able to come close, though less so in games that are very shader/texture heavy. In any case, coupled with NVIDIA’s 120W TDP power target, what we’re looking at is another aggressive move by NVIDIA with regards to power efficiency, bringing GTX 980 performance down from 165W to 120W.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/10474/GTX980_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>For the July 19th launch, much like their higher end cards NVIDIA is going to be launching with two designs and two price points. Officially the GTX 1060 starts at $249; this will be for partner custom cards, and I expect this will be for the usual single/dual fan open air cooler designs that we saw with the GTX 960. Meanwhile at $299 NVIDIA is launching a Founders Edition card, which implements a full blower.</p><p>However this is where the similarities end. Unlike the GTX 1080/1070 launch, the 19th is a hard launch for both the GTX 1060FE and for partner custom cards, and NVIDIA is expecting the bulk of the cards sold to be these custom cards. In this sense the GTX 1060 launch is more akin to the GTX 960 launch, as NVIDIA has more often than not opted to pass on producing reference cards for their mainstream cards.</p><p>In fact NVIDIA’s partners won’t even be selling the GTX 1060FE; the card will only be available through NVIDIA’s website. NVIDIA is calling the GTX 1060FE a “special limited edition” card, and though the company isn’t commenting on the matter, I strongly suspect that the GTX 1060FE is a limited run that NVIDIA will only be selling for a couple of months or so. NVIDIA has done similar things in the past, though ultimately when they curtail production is entirely up to them. I do wonder how NVIDIA’s partners feel about the company competing with them in the etail market, but with NVIDIA charging a significant $50/20% price premium, the partners have a lot of room to play with and improve on the NVIDIA reference design.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/10474/GeForce_GTX_1060_Back_1467822896_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>In terms of design, the GTX 1060 Founders Edition unsparingly ends up being a slightly smaller version of the common design shared by the GTX 1080 and GTX 1070 Founders Edition cards. The full care measures 9.75-inches long, 0.75-inches shorter than the GTX 1080/1070. Of that, only 6.75-inches is the actual reference PCB, with the final 3-inches housing the sole 6-pin power connector, the rest of the heatsink, and the radial blower fan. Given the size of the PCB, I wouldn’t be surprised to see some fairly small semi-custom cards come out of the partners, pairing up the PCB with smaller coolers. Meanwhile the display I/O configuration is identical to the other Pascal cards at 3 DP 1.4 ports, 1 HDMI 2.0b port, and 1 DL-DVI-D port. Also, the SLI connector is absent from this board.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/10474/GeForce_GTX_1060_3qtr_front_left_1467822736_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Finally, looking at the larger competitive and pricing landscape, the GTX 1060 is consistently priced with NVIDIA’s other Pascal cards, which is to say higher than the 900 series. Overall, GTX 1000 series pricing is closer to that of the 700 series, with the GTX 1060 launching at the same $249 price point the GTX 760 launched at back in 2013. As a result NVIDIA is going to miss the $199 mainstream sweet spot that the GTX 960 launched at, at least for the time being.</p><p>Whether that’s a blessing or not for AMD however remains to be seen. Overall GTX 1060 is clearly a shot across the bow at AMD’s recently launched Radeon RX 480, not quite overlapping it in price but otherwise going after the same target market with very aggressive performance and power targets. For various reasons 4GB RX 480 cards are in extremely short supply, and if this is still the case in 2 weeks, then the practical competition would be the $239 RX 480 versus the $249 GTX 1060 until AMD’s partners further ramp up the 4GB cards. Even then, I don’t know if things are cut and dry for the 4GB card given its more limited memory capacity.</p><p>Speaking of short supply though, it remains to be seen whether NVIDIA can keep the GTX 1060 in supply over the next couple of months. Certainly the first batches of cards will sell out on the 19th, as this has happened with previous launches. But what’s in question is whether NVIDIA and their partners can keep them in supply with the batches after that. So far NVIDIA has not been able to keep the GTX 1080 and GTX 1070 in supply – at the time of this writing, Newegg has a single card in stock – and the launch of the GTX 1060 won’t help that.</p><p>In practice NVIDIA has been receiving/processing GP106 for months, so the formal launch of GTX 1060 doesn’t change anything, but it none the less hints that NVIDIA is struggling at some point in their supply chain to meet demand. Officially the company has stated that they expect broad availability for the card and that they are ramping up supply “really fast,” but it’s definitely a case of where we’re going to have to wait and see. Ultimately buyers after the GTX 1060 may be better served snagging it on launch day, where the greatest number of units are available at once.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5xgJZtZqeumZm2onnAp6WorZ6YsrR5xp6dqKqTmnqowNdmaGluYGK3trjYZmhy</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>